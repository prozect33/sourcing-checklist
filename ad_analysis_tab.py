# path: app/ad_analysis.py
from __future__ import annotations

import hashlib
import json
import uuid
from dataclasses import dataclass
from typing import Dict, Iterable, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components
import altair as alt  # kept for compatibility (unused in Plotly chart)
import plotly.graph_objects as go

# ====== í‘œì¤€ ì»¬ëŸ¼ëª… ======
DATE_COL = "ë‚ ì§œ"
KW_COL = "í‚¤ì›Œë“œ"
SURF_COL = "ê´‘ê³  ë…¸ì¶œ ì§€ë©´"
SURF_SEARCH_VALUE = "ê²€ìƒ‰ ì˜ì—­"
IMP_COL = "ë…¸ì¶œìˆ˜"
CLK_COL = "í´ë¦­ìˆ˜"
COST_COL = "ê´‘ê³ ë¹„"
ORD_COL = "ì´ ì£¼ë¬¸ìˆ˜(14ì¼)"
REV_COL = "ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)"
REQUIRED_COLS = [DATE_COL, KW_COL, SURF_COL, IMP_COL, CLK_COL, COST_COL, ORD_COL, REV_COL]

# ====== ìë™(bottom/top) ê³„ì‚° íŒŒë¼ë¯¸í„°(ê³ ì •) ======
SMOOTH_DIVISOR = 70  # ì°½ = round(N / 70), í™€ìˆ˜, ìµœì†Œ7
SLOPE_Q = 0.64  # high ì„ê³„ ë¶„ìœ„
LOWBACK_DELTA = 0.24  # low_back_q = SLOPE_Q - LOWBACK_DELTA
MIN_RUN_FRAC = 0.04  # ìŠ¤íŒŒì´í¬ ë°©ì§€

# ====== ìˆ˜ë™ ìº¡ í”„ë¦¬ì…‹(ë¶„ë¦¬: bottom / top ê°ê°) ======
# ì›í•˜ëŠ” ë¶„í¬ë¡œ ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”. (0~1, ì˜¤ë¦„ì°¨ìˆœ ê¶Œì¥)
BOTTOM_Q_PRESETS: List[float] = [0.05, 0.10, 0.15, 0.20, 0.30]
TOP_Q_PRESETS:    List[float] = [0.05, 0.10, 0.15, 0.20, 0.30, 0.50]

# ì´ˆê¸° ê¸°ë³¸ê°’(ê°€ê¸‰ì  ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”)
DEFAULT_FLOOR_Q = BOTTOM_Q_PRESETS[0]   # í•˜ìœ„ q ê¸°ë³¸
DEFAULT_CEIL_Q  = TOP_Q_PRESETS[0]      # ìƒìœ„ 1-qì—ì„œì˜ q ê¸°ë³¸(=0.05â†’95% ë¶„ìœ„)

# ===================== ìœ í‹¸ =====================
def _to_int(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce").fillna(0).round(0).astype(int)


def _to_date(s: pd.Series) -> pd.Series:
    txt = s.astype(str).str.strip()
    dt_general = pd.to_datetime(txt, errors="coerce")

    digits = txt.str.replace(r"[^0-9]", "", regex=True)
    dt_8 = pd.to_datetime(digits.where(digits.str.len() == 8), format="%Y%m%d", errors="coerce")
    dt_6 = pd.to_datetime(digits.where(digits.str.len() == 6), format="%y%m%d", errors="coerce")

    num = pd.to_numeric(txt, errors="coerce").where(lambda x: x.between(20000, 60000))
    dt_serial = pd.to_datetime(num, unit="D", origin="1899-12-30", errors="coerce")

    dt = dt_general.fillna(dt_8).fillna(dt_6).fillna(dt_serial)
    return dt.dt.date


def _safe_div(a: float | int, b: float | int, default: float = 0.0) -> float:
    a, b = float(a), float(b)
    return default if b == 0 else a / b


def _moving_average(y: np.ndarray, window: int) -> np.ndarray:
    window = max(7, int(window))
    if window % 2 == 0:
        window += 1
    pad = window // 2
    ypad = np.pad(y, (pad, pad), mode="edge")
    kernel = np.ones(window, dtype=float) / window
    return np.convolve(ypad, kernel, mode="valid")


def _longest_true_run_by_x(mask: np.ndarray, x: np.ndarray) -> tuple[int, int]:
    best_span, best_s, cur_s = 0.0, -1, -1
    for i, v in enumerate(mask):
        if v and cur_s == -1:
            cur_s = i
        if (not v or i == len(mask) - 1) and cur_s != -1:
            e = i if not v else i
            span = float(x[e] - x[cur_s])
            if span > best_span:
                best_span, best_s = span, cur_s
            cur_s = -1

    if best_s == -1:
        return -1, -1

    e = best_s
    while e + 1 < len(mask) and mask[e + 1]:
        e += 1
    return best_s, e


def _nearest_preset_index(q: float) -> int:
    # bottom ì´ˆê¸° ì¸ë±ìŠ¤ëŠ” bottomìš© í”„ë¦¬ì…‹ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ê°’ìœ¼ë¡œ
    return int(np.argmin([abs(p - q) for p in BOTTOM_Q_PRESETS]))


def _quantile_x(x: np.ndarray, q: float) -> float:
    return float(np.quantile(x, float(np.clip(q, 0.0, 1.0))))

def _init_cap_indices() -> tuple[int, int]:
    # bottom: BOTTOM_Q_PRESETSì—ì„œ DEFAULT_FLOOR_Qì™€ ê°€ì¥ ê°€ê¹Œìš´ ì¸ë±ìŠ¤
    idx_floor = _nearest_preset_index(DEFAULT_FLOOR_Q)
    # top: TOP_Q_PRESETSì˜ ë§ˆì§€ë§‰ ê°’ì—ì„œ ì‹œì‘(ê°€ì¥ íƒ€ì´íŠ¸í•œ ìª½)
    idx_ceil = len(TOP_Q_PRESETS) - 1
    return idx_floor, idx_ceil

# ============== ë°ì´í„° ì ì¬/ì •ê·œí™” ==============
def _load_df(upload) -> pd.DataFrame:
    try:
        if upload.name.lower().endswith(".csv"):
            df = pd.read_csv(upload)
        else:
            df = pd.read_excel(upload)
    except Exception as e:
        raise ValueError(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    return df


def _normalize(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()
    df["date"] = _to_date(df[DATE_COL])
    df = df[df["date"].notna()].copy()
    df["keyword"] = df[KW_COL].astype(str).fillna("")
    df["surface"] = df[SURF_COL].astype(str).fillna("").str.strip()
    df["impressions"] = _to_int(df[IMP_COL])
    df["clicks"] = _to_int(df[CLK_COL])
    df["cost"] = _to_int(df[COST_COL])
    df["orders_14d"] = _to_int(df[ORD_COL])
    df["revenue_14d"] = _to_int(df[REV_COL])
    return df


# ============== ì§‘ê³„/ì§€í‘œ ==============
def _aggregate_kw(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:
    if df.empty:
        return pd.DataFrame(), {"total_cost": 0, "total_rev": 0, "total_orders": 0}

    date_min, date_max = df["date"].min(), df["date"].max()
    totals = {
        "total_cost": int(df["cost"].sum()),
        "total_rev": int(df["revenue_14d"].sum()),
        "total_orders": int(df["orders_14d"].sum()),
        "date_min": date_min,
        "date_max": date_max,
    }

    df_imp_pos = df[df["impressions"] > 0]
    days = df_imp_pos.groupby("keyword")["date"].nunique().reset_index(name="active_days")

    kw = (
        df.groupby(["keyword", "surface"], as_index=False)[
            ["impressions", "clicks", "cost", "orders_14d", "revenue_14d"]
        ]
        .sum()
        .merge(days, on="keyword", how="left")
    )

    kw["active_days"] = kw["active_days"].fillna(0).astype(int)
    kw["ctr"] = (kw["clicks"] / kw["impressions"]).replace([np.inf, -np.inf], 0).fillna(0).round(6)
    kw["cpc"] = (kw["cost"] / kw["clicks"]).replace([np.inf, -np.inf], 0).fillna(0).round(2)
    kw["roas_14d"] = (kw["revenue_14d"] / kw["cost"] * 100).replace([np.inf, -np.inf], 0).fillna(0).round(2)
    return kw, totals


# ============== ì»· ê³„ì‚°(ìë™ + ìº¡) ==============
@dataclass(frozen=True)
class CpcCuts:
    bottom: float
    top: float


def _compute_auto_cpc_cuts(kw: pd.DataFrame) -> Tuple[CpcCuts, pd.DataFrame]:
    """
    ìë™ ì»·(ì›ë³¸ ë¡œì§ ìœ ì§€):
      - bottom: high-ì„ê³„ ìµœì¥êµ¬ê°„ì„ low-ì„ê³„ë¡œ backtrackí•œ ì‹œì‘ì 
      - top   : argmax(y_n - x_n)
    ì£¼ì˜: ì—¬ê¸°ì„œëŠ” FLOOR ìº¡ì„ ì ìš©í•˜ì§€ ì•ŠìŒ(ìˆ˜ë™ ìº¡ì´ ë³„ë„ë¡œ ë“¤ì–´ê°).
    """
    conv = kw[kw["orders_14d"] > 0].sort_values("cpc").copy()
    if conv.empty:
        return CpcCuts(0.0, 0.0), conv

    total_conv_rev = float(conv["revenue_14d"].sum())
    conv["cum_rev"] = conv["revenue_14d"].cumsum()
    conv["cum_rev_share"] = (conv["cum_rev"] / (total_conv_rev if total_conv_rev > 0 else 1.0)).clip(0, 1)

    x = conv["cpc"].to_numpy(dtype=float)
    y = conv["cum_rev_share"].to_numpy(dtype=float)
    n = len(x)
    if n < 5:
        return CpcCuts(bottom=float(x[0]), top=float(x[-1])), conv

    # ----- top (ê¸°ì¡´ ìœ ì§€) -----
    x_n = (x - x.min()) / (x.max() - x.min() + 1e-12)
    y_n = (y - y.min()) / (y.max() - y.min() + 1e-12)
    idx_top = int(np.argmax(y_n - x_n))

    # ----- bottom (ì‹¬í”Œ íˆìŠ¤í…Œë¦¬ì‹œìŠ¤, floor ì ìš© ì—†ìŒ) -----
    smooth_win = max(7, int(round(n / SMOOTH_DIVISOR)))
    if smooth_win % 2 == 0:
        smooth_win += 1

    y_s = _moving_average(y, smooth_win)
    slope = np.gradient(y_s, x)

    pos = slope[slope > 0]
    if pos.size == 0 or not np.any(np.isfinite(pos)):
        idx_bottom = 0
    else:
        high_thr = float(np.quantile(pos, float(np.clip(SLOPE_Q, 0.55, 0.9))))
        s_high, e_high = _longest_true_run_by_x(slope >= high_thr, x)

        if s_high == -1:
            high_thr = float(np.quantile(pos, 0.55))
            s_high, e_high = _longest_true_run_by_x(slope >= high_thr, x)

        if s_high == -1:
            idx_bottom = 0
        else:
            low_back_q = float(np.clip(SLOPE_Q - LOWBACK_DELTA, 0.15, 0.45))
            low_thr = float(np.quantile(pos, low_back_q))
            mask_low = slope >= low_thr

            s = s_high
            while s - 1 >= 0 and mask_low[s - 1]:
                s -= 1

            e = s
            while e + 1 < len(mask_low) and mask_low[e + 1]:
                e += 1

            min_run = max(2, int(np.ceil(n * MIN_RUN_FRAC)))
            if (e - s + 1) < min_run:
                e = min(n - 1, s + min_run - 1)

            idx_bottom = int(s)

    return CpcCuts(bottom=float(x[idx_bottom]), top=float(x[idx_top])), conv


def _apply_caps(auto_cuts: CpcCuts, conv: pd.DataFrame, floor_q: float, ceil_q: float) -> CpcCuts:
    """
    ìˆ˜ë™ ìº¡:
      - bottom = max(auto_bottom, quantile(cpc, floor_q))
      - top    = min(auto_top,    quantile(cpc, 1 - ceil_q))
    """
    x = conv["cpc"].to_numpy(float)

    floor_x = _quantile_x(x, floor_q)
    ceil_x = _quantile_x(x, 1.0 - ceil_q)

    bottom = max(float(auto_cuts.bottom), float(floor_x))
    top = min(float(auto_cuts.top), float(ceil_x))

    if top <= bottom:
        top = float(x[-1])
        st.warning("top â‰¤ bottom ì´ ë˜ì–´ topì„ ìµœëŒ“ê°’ìœ¼ë¡œ ì™„í™”í–ˆìŠµë‹ˆë‹¤. (CEIL ë‹¨ê³„ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì˜®ê²¨ë³´ì„¸ìš”)")

    return CpcCuts(bottom=bottom, top=top)


# ====== (ì‹ ê·œ) í›„ë³´ ì„  ìƒì„±/ì¤‘ë³µ ì œê±° ======
def _build_candidate_lines(conv: pd.DataFrame, auto_cuts: CpcCuts) -> tuple[List[float], List[float]]:
    """
    why: í™”ì‚´í‘œ ëŒ€ì‹  ëª¨ë“  që‹¨ê³„ ì„ ì„ ë¯¸ë¦¬ ìƒì„±í•´ ë³´ì—¬ì£¼ê¸° ìœ„í•¨.
    - ê° qì— ëŒ€í•´ _apply_capsë¥¼ ê±°ì¹œ bottom/top ê°’ì„ ì‚°ì¶œ
    - ì†Œìˆ˜ 2ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼ í›„ setìœ¼ë¡œ ì¤‘ë³µ ì œê±°, ì •ë ¬
    """
    x = conv["cpc"].to_numpy(float)

    bottom_vals = []
    for q in BOTTOM_Q_PRESETS:
        floor_x = _quantile_x(x, q)
        bottom_vals.append(max(float(auto_cuts.bottom), float(floor_x)))

    top_vals = []
    for q in TOP_Q_PRESETS:
        ceil_x = _quantile_x(x, 1.0 - q)
        top_vals.append(min(float(auto_cuts.top), float(ceil_x)))

    # ì¤‘ë³µ ì œê±°(ì†Œìˆ˜ 2ìë¦¬ ê¸°ì¤€) ë° ì •ë ¬
    def _dedup_sorted(vals: List[float]) -> List[float]:
        rounded = [round(v, 2) for v in vals]
        uniq = sorted(dict.fromkeys(rounded))
        return uniq

    return _dedup_sorted(bottom_vals), _dedup_sorted(top_vals)


def _nearest_index(values: List[float], target: float) -> int:
    if not values:
        return 0
    return int(np.argmin([abs(v - target) for v in values]))


# ============== ì§€í‘œ/í‘œì‹œ ==============
def _search_shares_for_cuts(kw: pd.DataFrame, cuts: CpcCuts) -> Dict[str, float]:
    kw_search_all = kw[kw["surface"] == SURF_SEARCH_VALUE].copy()
    kw_click = kw_search_all[kw_search_all["clicks"] > 0].copy()

    total_cost_all = float(kw["cost"].sum())
    total_rev_all = float(kw["revenue_14d"].sum())

    def _share(mask: pd.Series, col: str, denom: float) -> float:
        num = float(kw_click.loc[mask, col].sum())
        return round(_safe_div(num, denom, 0.0) * 100, 2)

    mask_bottom = kw_click["cpc"] <= cuts.bottom
    mask_top = kw_click["cpc"] >= cuts.top

    return {
        "rev_share_bottom": _share(mask_bottom, "revenue_14d", total_rev_all),
        "cost_share_bottom": _share(mask_bottom, "cost", total_cost_all),
        "rev_share_top": _share(mask_top, "revenue_14d", total_rev_all),
        "cost_share_top": _share(mask_top, "cost", total_cost_all),
    }


def _aov_p50(conv: pd.DataFrame) -> float:
    orders = conv["orders_14d"]
    rev = conv["revenue_14d"]
    valid = rev[orders > 0] / orders[orders > 0]
    return float(valid.quantile(0.5)) if not valid.empty else 0.0


def _compute_exclusions(
    kw: pd.DataFrame, cuts: CpcCuts, aov_p50_value: float, breakeven_roas: float
) -> Dict[str, pd.DataFrame]:
    ex_a = kw[(kw["orders_14d"] == 0) & (kw["cpc"] >= cuts.top)].copy()
    ex_b = kw[(kw["orders_14d"] == 0) & (kw["cpc"] <= cuts.bottom) & (kw["clicks"] >= 1)].copy()

    cpc_global_p50 = float(kw.loc[kw["clicks"] > 0, "cpc"].quantile(0.5)) if (kw["clicks"] > 0).any() else 0.0
    ex_c = kw[kw["orders_14d"] == 0].copy()
    ex_c["next_click_cost"] = np.where(ex_c["cpc"] > 0, ex_c["cpc"], cpc_global_p50)
    ex_c["cost_after_1click"] = ex_c["cost"] + ex_c["next_click_cost"]
    ex_c["roas_if_1_order"] = (
        (aov_p50_value / ex_c["cost_after_1click"] * 100)
        .replace([np.inf, -np.inf], 0)
        .fillna(0)
        .round(2)
        if aov_p50_value > 0
        else 0.0
    )
    ex_c = ex_c[ex_c["roas_if_1_order"] <= float(breakeven_roas)].copy()

    ex_d = kw[(kw["roas_14d"] > 0) & (kw["roas_14d"] < float(breakeven_roas))].copy()
    return {"a": ex_a, "b": ex_b, "c": ex_c, "d": ex_d}


def _display_table(title: str, dff: pd.DataFrame, extra: Iterable[str] | None = None) -> None:
    cols = [
        "keyword",
        "surface",
        "active_days",
        "impressions",
        "clicks",
        "cost",
        "orders_14d",
        "revenue_14d",
        "ctr",
        "cpc",
        "roas_14d",
    ]
    if extra:
        cols += list(extra)
    st.markdown(f"#### {title} ({len(dff)}ê°œ)")
    if dff.empty:
        return
    st.dataframe(dff.sort_values("cost", ascending=False)[cols].head(200), use_container_width=True, hide_index=True)


def _gather_exclusion_keywords(exclusions: Dict[str, pd.DataFrame]) -> List[str]:
    seq: List[str] = []
    for label in ["a", "b", "c", "d"]:
        df = exclusions.get(label, pd.DataFrame())
        if not df.empty:
            seq.extend(df["keyword"].astype(str).tolist())
    return list(dict.fromkeys(seq))


def _format_keywords_line_exact(words: Iterable[str]) -> str:
    return ",\u200b".join([w for w in words])


def _copy_to_clipboard_button(label: str, text: str, key: str) -> None:
    payload = json.dumps(text)
    html = f"""
    <div style="display:flex;align-items:center;gap:8px;">
      <button id="copybtn-{key}" role="button" aria-label="{label}"
        style="display:inline-flex;align-items:center;justify-content:center;padding:8px 12px;font-size:14px;line-height:1.25;border:1px solid rgba(49,51,63,0.2);border-radius:8px;background:#ffffff;cursor:pointer;box-shadow: 0 1px 2px rgba(0,0,0,0.04);transition: transform .02s, box-shadow .15s, background .15s;">
        {label}
      </button>
      <span id="copystat-{key}" style="font-size:13px;color:#4CAF50;"></span>
    </div>
    <script>
      const txt_{key} = {payload};
      const btn_{key} = document.getElementById("copybtn-{key}");
      const stat_{key} = document.getElementById("copystat-{key}");
      btn_{key}.onclick = async () => {{
        try {{ await navigator.clipboard.writeText(txt_{key}); stat_{key}.textContent = "ë³µì‚¬ë¨"; }}
        catch (e) {{
          const area = document.createElement('textarea');
          area.value = txt_{key}; area.style.position = 'fixed'; area.style.top = '-1000px';
          document.body.appendChild(area); area.focus(); area.select(); document.execCommand('copy');
          document.body.removeChild(area); stat_{key}.textContent = "ë³µì‚¬ë¨";
        }}
        setTimeout(()=> stat_{key}.textContent = "", 2000);
      }};
    </script>
    """
    components.html(html, height=56)


def _render_exclusion_union(exclusions: Dict[str, pd.DataFrame]) -> None:
    st.markdown("### 4) ì œì™¸ í‚¤ì›Œë“œ (í†µí•© Â· í•œë°”êµ¬ë‹ˆ Â· ì¤‘ë³µ ì œê±°)")
    all_words = _gather_exclusion_keywords(exclusions)
    total = len(all_words)
    if total == 0:
        return
    line = _format_keywords_line_exact(all_words)
    _copy_to_clipboard_button(f"[ë³µì‚¬í•˜ê¸°] ì´{total}ê°œ", line, key="ex_union_copy")


# ============== Plotly ì°¨íŠ¸ (ê°œì„ : ë‹¤ì¤‘ ì„  + ê°•ì¡°) ==============
def _plot_cpc_curve_plotly_multi(
    conv: pd.DataFrame,
    selected: CpcCuts,
    bottoms: List[float],
    tops: List[float],
) -> None:
    # ìƒ‰ìƒ ì§€ì •(Plotly ê¸°ë³¸ íŒ”ë ˆíŠ¸ ê³„ì—´)
    BOTTOM_COLOR = "#1f77b4"  # íŒŒë‘
    TOP_COLOR = "#d62728"     # ë¹¨ê°•

    x = conv["cpc"].to_numpy(float)
    y = conv["cum_rev_share"].to_numpy(float)

    fig = go.Figure()
    # ì›ë³¸ ê³¡ì„ 
    fig.add_trace(
        go.Scatter(
            x=x, y=y, mode="lines", name="cum_rev_share",
            hovertemplate="CPC=%{x:.0f}<br>Share=%{y:.2%}<extra></extra>"
        )
    )

    # ---- í›„ë³´ì„ (ì˜…ê²Œ) ----
    # bottom í›„ë³´ = íŒŒë‘ ì ì„ 
    for b in bottoms:
        fig.add_vline(x=b, line_dash="dot", opacity=0.35, line_color=BOTTOM_COLOR, line_width=1)

    # top í›„ë³´ = ë¹¨ê°• íŒŒì„ 
    for t in tops:
        fig.add_vline(x=t, line_dash="dash", opacity=0.35, line_color=TOP_COLOR, line_width=1)

    # ---- ì„ íƒì„ (ì§„í•˜ê²Œ) ----
    # bottom ì„ íƒ = íŒŒë‘ ì‹¤ì„ (ê°•ì¡°)
    fig.add_vline(x=selected.bottom, line_dash="solid", opacity=1.0, line_color=BOTTOM_COLOR, line_width=3)
    # top ì„ íƒ = ë¹¨ê°• ì‹¤ì„ (ê°•ì¡°)
    fig.add_vline(x=selected.top, line_dash="solid", opacity=1.0, line_color=TOP_COLOR, line_width=3)

    # ì„ íƒ í¬ì¸íŠ¸ ë§ˆì»¤(ìƒ‰ ë§¤ì¹­)
    idx_b = int(np.argmin(np.abs(x - selected.bottom)))
    idx_t = int(np.argmin(np.abs(x - selected.top)))
    fig.add_trace(
        go.Scatter(
            x=[x[idx_b]], y=[y[idx_b]],
            mode="markers",
            name="bottom selected",
            marker=dict(symbol="triangle-up", size=12, color=BOTTOM_COLOR),  # íŒŒë‘
            hovertemplate="CPC=%{x:.0f}<br>Share=%{y:.2%}<extra></extra>",
            showlegend=False,
        )
    )
    fig.add_trace(
        go.Scatter(
            x=[x[idx_t]], y=[y[idx_t]],
            mode="markers",
            name="top selected",
            marker=dict(symbol="triangle-up", size=12, color=TOP_COLOR),     # ë¹¨ê°•
            hovertemplate="CPC=%{x:.0f}<br>Share=%{y:.2%}<extra></extra>",
            showlegend=False,
        )
    )

    fig.update_layout(
        height=380,
        margin=dict(l=20, r=20, t=30, b=20),
        xaxis_title="CPC",
        yaxis_title="ëˆ„ì ë§¤ì¶œë¹„ì¤‘",
        yaxis=dict(tickformat=".0%"),
        showlegend=False,
    )
    st.plotly_chart(fig, use_container_width=True)

# ============== Streamlit íƒ­ ==============
def render_ad_analysis_tab(supabase):
    st.subheader("ê´‘ê³ ë¶„ì„ (ì´ 14ì¼ ê¸°ì¤€)")

    # --- ì…ë ¥ ìœ„ì ¯ ---
    up = st.file_uploader("ë¡œìš°ë°ì´í„° ì—…ë¡œë“œ (xlsx/csv)", type=["xlsx", "csv"], key="ad_up")
    breakeven_roas = st.number_input("ì†ìµë¶„ê¸° ROAS", min_value=0.0, value=0.0, step=10.0, key="ad_be")

    # --- ë¶„ì„ ì„¸ì…˜ ìƒíƒœ (ë²„íŠ¼ì˜ ì¼íšŒì„± íšŒí”¼) ---
    if "ad_run_started" not in st.session_state:
        st.session_state["ad_run_started"] = False

    run_clicked = st.button("ğŸ” ë¶„ì„í•˜ê¸°", key="ad_run", use_container_width=True)
    if run_clicked:
        # why: rerun ë•Œ ë²„íŠ¼ê°’ì€ Falseë¡œ ë–¨ì–´ì§ â†’ ì„¸ì…˜ í”Œë˜ê·¸ë¡œë§Œ íŒì •
        st.session_state["ad_run_started"] = True

    # --- ì¡°ê¸° ì¢…ë£Œ ê²Œì´íŠ¸ë¥¼ ì„¸ì…˜ í”Œë˜ê·¸ë¡œ ---
    if not st.session_state["ad_run_started"]:
        return

    # --- ê²€ì¦ ---
    if up is None:
        st.error("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return
    try:
        df_raw = _load_df(up)
        df = _normalize(df_raw)
    except ValueError as e:
        st.error(str(e))
        return
    if df.empty:
        st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- ì§‘ê³„ ---
    kw, totals = _aggregate_kw(df)

    st.markdown("### 1) ê¸°ë³¸ ì„±ê³¼ ì§€í‘œ")
    st.caption(f"ê¸°ê°„: {totals['date_min']} ~ {totals['date_max']}")
    total_cost = totals["total_cost"]
    total_rev = totals["total_rev"]
    total_orders = totals["total_orders"]

    def _row(name: str, sub: pd.DataFrame) -> Dict[str, float | int | str]:
        c = int(sub["cost"].sum())
        r = int(sub["revenue_14d"].sum())
        o = int(sub["orders_14d"].sum())
        return {
            "ì˜ì—­": name,
            "ê´‘ê³ ë¹„": c,
            "ê´‘ê³ ë¹„ë¹„ìœ¨(%)": round(_safe_div(c, total_cost) * 100, 2),
            "ë§¤ì¶œ": r,
            "ë§¤ì¶œë¹„ìœ¨(%)": round(_safe_div(r, total_rev) * 100, 2),
            "ì£¼ë¬¸": o,
            "ì£¼ë¬¸ë¹„ìœ¨(%)": round(_safe_div(o, total_orders) * 100, 2),
            "ROAS": round(_safe_div(r, c) * 100, 2),
        }

    rows = [
        _row("ì „ì²´", df),
        _row("ê²€ìƒ‰", df[df["surface"] == SURF_SEARCH_VALUE]),
        _row("ë¹„ê²€ìƒ‰", df[df["surface"] != SURF_SEARCH_VALUE]),
    ]
    st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

    # --- ì»· & ìº¡ ---
    st.markdown("### 2) CPC-ëˆ„ì ë§¤ì¶œ ë¹„ì¤‘ & ì»· (ëª¨ë“  qì„  ë¯¸ë¦¬ë³´ê¸° + ìë™ ë²„íŠ¼ ì„ íƒ)")
    auto_cuts, conv = _compute_auto_cpc_cuts(kw)
    if conv.empty:
        st.caption("ì „í™˜ ë°œìƒ í‚¤ì›Œë“œê°€ ì—†ì–´ ì»·ì€ 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
        return

    # í›„ë³´ ì„  ìƒì„±(ì¤‘ë³µ ì œê±°)
    bottom_lines, top_lines = _build_candidate_lines(conv, auto_cuts)

    # ìµœì´ˆ ì§„ì… ì‹œ ì„ íƒ ì¸ë±ìŠ¤ ì´ˆê¸°í™”(ê¸°ì¡´ ê¸°ë³¸ qì— ê°€ì¥ ê°€ê¹Œìš´ ê°’)
    if "sel_bottom_idx" not in st.session_state or "sel_top_idx" not in st.session_state:
        x = conv["cpc"].to_numpy(float)
        # ê¸°ë³¸ që¡œ ê³„ì‚°ëœ ì‹¤ì œ ê°’
        default_bottom = max(float(auto_cuts.bottom), _quantile_x(x, DEFAULT_FLOOR_Q))
        default_top = min(float(auto_cuts.top), _quantile_x(x, 1.0 - DEFAULT_CEIL_Q))
        st.session_state["sel_bottom_idx"] = _nearest_index(bottom_lines, round(default_bottom, 2))
        st.session_state["sel_top_idx"] = _nearest_index(top_lines, round(default_top, 2))

    # â–¼ ì¶”ê°€: ì¸ë±ìŠ¤ ë³´ì •(í”„ë¦¬ì…‹ ë³€ê²½/ì¤‘ë³µ ì œê±°ë¡œ í›„ë³´ ê°œìˆ˜ ë‹¬ë¼ì§ˆ ë•Œ IndexError ë°©ì§€)
    def _clamp(i: int, n: int) -> int:
        return 0 if n <= 0 else int(max(0, min(i, n - 1)))

    st.session_state["sel_bottom_idx"] = _clamp(st.session_state["sel_bottom_idx"], len(bottom_lines))
    st.session_state["sel_top_idx"] = _clamp(st.session_state["sel_top_idx"], len(top_lines))

    # í›„ë³´ì„ ì´ ë¹„ì–´ìˆëŠ” ê·¹ë‹¨ ìƒí™© ì²˜ë¦¬(ë“œë¬¾)
    if len(bottom_lines) == 0 or len(top_lines) == 0:
        st.warning("í›„ë³´ ì„ ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë¶„í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # ìë™ ë²„íŠ¼ ìƒì„±(ì„  ê°œìˆ˜ë§Œí¼)
    c1, c2 = st.columns(2)
    with c1:
        st.caption(f"**Bottom floor** â€¢ {len(bottom_lines)}ê°œ í›„ë³´")
        # ë²„íŠ¼ë“¤ì„ ê²©ìë¡œ ìë™ ë°°ì¹˜
        ncols = min(10, len(bottom_lines))
        idx = 0
        rows = (len(bottom_lines) + ncols - 1) // ncols
        for _ in range(rows):
            cols = st.columns(ncols)
            for c in range(ncols):
                if idx >= len(bottom_lines):
                    break
                label = f"B{idx + 1}"
                if cols[c].button(label, key=f"btn_b_{idx}"):
                    st.session_state["sel_bottom_idx"] = idx  # why: ì„ íƒ ìœ ì§€
                idx += 1
        b_idx = st.session_state["sel_bottom_idx"]  # ë³´ì •ëœ ì¸ë±ìŠ¤ ì‚¬ìš©
        st.caption(f"ì„ íƒ: B{b_idx + 1} Â· {bottom_lines[b_idx]:.2f}ì›")

    with c2:
        st.caption(f"**Top ceiling** â€¢ {len(top_lines)}ê°œ í›„ë³´")
        ncols = min(10, len(top_lines))
        idx = 0
        rows = (len(top_lines) + ncols - 1) // ncols
        for _ in range(rows):
            cols = st.columns(ncols)
            for c in range(ncols):
                if idx >= len(top_lines):
                    break
                label = f"T{idx + 1}"
                if cols[c].button(label, key=f"btn_t_{idx}"):
                    st.session_state["sel_top_idx"] = idx
                idx += 1
        t_idx = st.session_state["sel_top_idx"]  # ë³´ì •ëœ ì¸ë±ìŠ¤ ì‚¬ìš©
        st.caption(f"ì„ íƒ: T{t_idx + 1} Â· {top_lines[t_idx]:.2f}ì›")

    # ì„ íƒê°’ í™•ì •(ë³´ì • ì¸ë±ìŠ¤ë¡œ)
    sel_cuts = CpcCuts(
        bottom=float(bottom_lines[b_idx]),
        top=float(top_lines[t_idx]),
    )

    # --- ì°¨íŠ¸ & ì§€í‘œ ---
    _plot_cpc_curve_plotly_multi(conv, sel_cuts, bottom_lines, top_lines)

    shares = _search_shares_for_cuts(kw, sel_cuts)
    aov50 = _aov_p50(conv)

    st.caption("ë¹„ì¤‘ ë¶„ëª¨: ì „ì²´ ì±„ë„(ê²€ìƒ‰+ë¹„ê²€ìƒ‰), ë¶„ì: ê²€ìƒ‰ ì˜ì—­(í´ë¦­>0) ì¤‘ CPC ì¡°ê±´ ì¶©ì¡± í‚¤ì›Œë“œ í•©")
    st.markdown(
        f"""
- **CPC_cut bottom:** {round(sel_cuts.bottom, 2)}ì›  
  Â· ê²€ìƒ‰ ê´‘ê³  ë§¤ì¶œ ë¹„ì¤‘ {shares['rev_share_bottom']}%  
  Â· ê²€ìƒ‰ ê´‘ê³  ê´‘ê³ ë¹„ ë¹„ì¤‘ {shares['cost_share_bottom']}%

- **CPC_cut top:** {round(sel_cuts.top, 2)}ì›  
  Â· ê²€ìƒ‰ ê´‘ê³  ë§¤ì¶œ ë¹„ì¤‘ {shares['rev_share_top']}%  
  Â· ê²€ìƒ‰ ê´‘ê³  ê´‘ê³ ë¹„ ë¹„ì¤‘ {shares['cost_share_top']}%
"""
    )

    # --- ì œì™¸ í‚¤ì›Œë“œ ---
    st.markdown("### 3) ì œì™¸ í‚¤ì›Œë“œ")
    exclusions = _compute_exclusions(kw, sel_cuts, aov50, float(breakeven_roas))
    _display_table("a) CPC_cut top ì´ìƒ ì „í™˜ 0", exclusions["a"])
    _display_table("b) CPC_cut bottom ì´í•˜ ì „í™˜ 0", exclusions["b"])
    _display_table("c) ì „í™˜ ì‹œ ì†ìµ ROAS ë¯¸ë‹¬", exclusions["c"], extra=["roas_if_1_order"])
    _display_table("d) ì†ìµ ROAS ë¯¸ë‹¬", exclusions["d"])

    _render_exclusion_union(exclusions)

    # --- ì €ì¥ (ì„ íƒ) ---
    with st.expander("ğŸ’¾ ì €ì¥ (ì„ íƒ)", expanded=False):
        c1, c2 = st.columns([2, 3])
        with c1:
            product_name = st.text_input("ìƒí’ˆëª…", value="", key="ad_product")
        with c2:
            note = st.text_input("ë©”ëª¨", value="", key="ad_note")
        can_save = bool(product_name.strip())
        save_btn = st.button("âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥", disabled=not can_save, key="ad_save")

        if save_btn and can_save:
            try:
                _save_to_supabase(
                    supabase,
                    upload=up,
                    product_name=product_name,
                    note=note,
                    totals=totals,
                    breakeven_roas=float(breakeven_roas),
                    cuts=sel_cuts,
                    shares=shares,
                    aov_p50_value=aov50,
                    kw=kw,
                    exclusions=exclusions,
                )
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")
