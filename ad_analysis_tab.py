# app/ad_analysis.py
from __future__ import annotations

import hashlib
import uuid
import json
from dataclasses import dataclass
from typing import Dict, Iterable, Tuple, List

import numpy as np
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components
import altair as alt

# ====== ì›ì‹œ ë°ì´í„° ì»¬ëŸ¼ëª…(í‘œì¤€) ======
DATE_COL = "ë‚ ì§œ"
KW_COL = "í‚¤ì›Œë“œ"
SURF_COL = "ê´‘ê³  ë…¸ì¶œ ì§€ë©´"
SURF_SEARCH_VALUE = "ê²€ìƒ‰ ì˜ì—­"
IMP_COL = "ë…¸ì¶œìˆ˜"
CLK_COL = "í´ë¦­ìˆ˜"
COST_COL = "ê´‘ê³ ë¹„"
ORD_COL = "ì´ ì£¼ë¬¸ìˆ˜(14ì¼)"
REV_COL = "ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)"

REQUIRED_COLS = [DATE_COL, KW_COL, SURF_COL, IMP_COL, CLK_COL, COST_COL, ORD_COL, REV_COL]

# ===================== ìœ í‹¸ =====================
def _to_int(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce").fillna(0).round(0).astype(int)

def _to_date(s: pd.Series) -> pd.Series:
    txt = s.astype(str).str.strip()
    dt_general = pd.to_datetime(txt, errors="coerce")
    digits = txt.str.replace(r"[^0-9]", "", regex=True)
    dt_8 = pd.to_datetime(digits.where(digits.str.len() == 8), format="%Y%m%d", errors="coerce")
    dt_6 = pd.to_datetime(digits.where(digits.str.len() == 6), format="%y%m%d", errors="coerce")
    num = pd.to_numeric(txt, errors="coerce").where(lambda x: x.between(20000, 60000))
    dt_serial = pd.to_datetime(num, unit="D", origin="1899-12-30", errors="coerce")
    dt = dt_general.fillna(dt_8).fillna(dt_6).fillna(dt_serial)
    return dt.dt.date

def _safe_div(a: float | int, b: float | int, default: float = 0.0) -> float:
    a, b = float(a), float(b)
    return default if b == 0 else a / b

def _median_1d(s: pd.Series) -> float:
    return float(np.round(s.median(), 1)) if not s.empty else 0.0

# ---- Longest Uphill Helpers (ì™œ: bottom ì‹œì‘ì  ì•ˆì •í™”) ----
def _moving_average(y: np.ndarray, window: int) -> np.ndarray:
    """ì™œ: ì¡ìŒì„ ëˆŒëŸ¬ ë‹¨ê¸° ìŠ¤íŒŒì´í¬ì— ì˜í•œ ì˜¤ì¸ì‹ ë°©ì§€."""
    window = max(7, int(window))
    if window % 2 == 0:
        window += 1
    pad = window // 2
    ypad = np.pad(y, (pad, pad), mode="edge")
    kernel = np.ones(window, dtype=float) / window
    return np.convolve(ypad, kernel, mode="valid")

def _longest_true_run(mask: np.ndarray) -> tuple[int, int]:
    """Trueì˜ ìµœì¥ ì—°ì† êµ¬ê°„ [start, end] (end í¬í•¨), ì—†ìœ¼ë©´ (-1,-1)."""
    best_len, best_start, cur_start = 0, -1, -1
    for i, v in enumerate(mask):
        if v and cur_start == -1:
            cur_start = i
        if not v and cur_start != -1:
            L = i - cur_start
            if L > best_len:
                best_len, best_start = L, cur_start
            cur_start = -1
    if cur_start != -1:
        L = len(mask) - cur_start
        if L > best_len:
            best_len, best_start = L, cur_start
    if best_start == -1:
        return -1, -1
    return best_start, best_start + best_len - 1

# ============== ë°ì´í„° ì ì¬/ì •ê·œí™” ==============
def _load_df(upload) -> pd.DataFrame:
    try:
        if upload.name.lower().endswith(".csv"):
            df = pd.read_csv(upload)
        else:
            df = pd.read_excel(upload)
    except Exception as e:
        raise ValueError(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    return df

def _normalize(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()
    df["date"] = _to_date(df[DATE_COL])
    df = df[df["date"].notna()].copy()
    df["keyword"] = df[KW_COL].astype(str).fillna("")
    df["surface"] = df[SURF_COL].astype(str).fillna("").str.strip()
    df["impressions"] = _to_int(df[IMP_COL])
    df["clicks"] = _to_int(df[CLK_COL])
    df["cost"] = _to_int(df[COST_COL])
    df["orders_14d"] = _to_int(df[ORD_COL])
    df["revenue_14d"] = _to_int(df[REV_COL])
    return df

# ============== ì§‘ê³„/ì§€í‘œ ==============
def _aggregate_kw(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:
    if df.empty:
        return pd.DataFrame(), {"total_cost": 0, "total_rev": 0, "total_orders": 0}
    date_min, date_max = df["date"].min(), df["date"].max()
    totals = {
        "total_cost": int(df["cost"].sum()),
        "total_rev": int(df["revenue_14d"].sum()),
        "total_orders": int(df["orders_14d"].sum()),
        "date_min": date_min,
        "date_max": date_max,
    }
    df_imp_pos = df[df["impressions"] > 0]
    days = df_imp_pos.groupby("keyword")["date"].nunique().reset_index(name="active_days")
    kw = (
        df.groupby(["keyword", "surface"], as_index=False)[
            ["impressions", "clicks", "cost", "orders_14d", "revenue_14d"]
        ]
        .sum()
        .merge(days, on="keyword", how="left")
    )
    kw["active_days"] = kw["active_days"].fillna(0).astype(int)
    kw["ctr"] = (kw["clicks"] / kw["impressions"]).replace([np.inf, -np.inf], 0).fillna(0).round(6)
    kw["cpc"] = (kw["cost"] / kw["clicks"]).replace([np.inf, -np.inf], 0).fillna(0).round(2)
    kw["roas_14d"] = (kw["revenue_14d"] / kw["cost"] * 100).replace([np.inf, -np.inf], 0).fillna(0).round(2)
    return kw, totals

@dataclass(frozen=True)
class CpcCuts:
    bottom: float
    top: float

def _compute_cpc_cuts(kw: pd.DataFrame) -> Tuple[CpcCuts, pd.DataFrame]:
    """
    bottom: 'ê°€ì¥ ì˜¤ë˜ ê°€íŒŒë¥¸ ì˜¤ë¥´ë§‰' ì‹œì‘ì (ìŠ¤ë¬´ë”©â†’ê¸°ìš¸ê¸°â†’ìƒìœ„ 0.75 ë¶„ìœ„â†’ìµœì¥ run ì‹œì‘)
    top   : ì •ê·œí™” í›„ y_n - x_n ìµœëŒ€ ì§€ì (ê¸°ì¡´ ìœ ì§€)
    """
    conv = kw[kw["orders_14d"] > 0].sort_values("cpc").copy()
    if conv.empty:
        return CpcCuts(0.0, 0.0), conv

    total_conv_rev = float(conv["revenue_14d"].sum())
    conv["cum_rev"] = conv["revenue_14d"].cumsum()
    conv["cum_rev_share"] = (conv["cum_rev"] / (total_conv_rev if total_conv_rev > 0 else 1.0)).clip(0, 1)

    x = conv["cpc"].to_numpy(dtype=float)
    y = conv["cum_rev_share"].to_numpy(dtype=float)

    if len(x) < 4:
        return CpcCuts(bottom=float(x[0]), top=float(x[-1])), conv

    # ----- top (ê¸°ì¡´ ë°©ì‹ ìœ ì§€) -----
    x_n = (x - x.min()) / (x.max() - x.min() + 1e-12)
    y_n = (y - y.min()) / (y.max() - y.min() + 1e-12)
    idx_top = int(np.argmax(y_n - x_n))

    # ----- bottom (Longest Uphill Start) -----
    n = len(x)
    smooth_win = max(7, int(round(n / 60)))
    if smooth_win % 2 == 0:
        smooth_win += 1

    y_s = _moving_average(y, smooth_win)
    slope = np.gradient(y_s, x)  # x ë‹¨ì¡° ì¦ê°€ ê°€ì •

    pos = slope[slope > 0]
    if pos.size == 0 or not np.any(np.isfinite(pos)):
        idx_bottom = 0
    else:
        # 1ì°¨: 0.75 ë¶„ìœ„
        thr = float(np.quantile(pos, 0.75))
        mask = slope >= thr
        s, e = _longest_true_run(mask)

        # ì‹¤íŒ¨ ì‹œ 0.60ë¡œ ì™„í™”
        if s == -1:
            thr = float(np.quantile(pos, 0.60))
            mask = slope >= thr
            s, e = _longest_true_run(mask)

        if s == -1:
            idx_bottom = 0
        else:
            # ë„ˆë¬´ ì§§ìœ¼ë©´ ìµœì†Œ ê¸¸ì´ ë³´ì •(ì™œ: ìˆœê°„ ìŠ¤íŒŒì´í¬ ë°©ì§€)
            min_run = max(2, int(np.ceil(n * 0.03)))
            if (e - s + 1) < min_run:
                e = min(n - 1, s + min_run - 1)
            idx_bottom = s

    cuts = CpcCuts(bottom=float(x[idx_bottom]), top=float(x[idx_top]))
    return cuts, conv

def _search_shares_for_cuts(kw: pd.DataFrame, cuts: CpcCuts) -> Dict[str, float]:
    """
    ë¶„ëª¨: ì „ì²´ ì±„ë„ í•©(ê²€ìƒ‰+ë¹„ê²€ìƒ‰)
    ë¶„ì: ê²€ìƒ‰ ì˜ì—­ + í´ë¦­>0, CPC ì¡°ê±´(â‰¤ bottom / â‰¥ top) ì¶©ì¡± í‚¤ì›Œë“œ í•©
    """
    kw_search_all = kw[kw["surface"] == SURF_SEARCH_VALUE].copy()
    kw_click = kw_search_all[kw_search_all["clicks"] > 0].copy()

    total_cost_all = float(kw["cost"].sum())
    total_rev_all = float(kw["revenue_14d"].sum())

    def _share(mask: pd.Series, col: str, denom: float) -> float:
        num = float(kw_click.loc[mask, col].sum())
        return round(_safe_div(num, denom, 0.0) * 100, 2)

    mask_bottom = kw_click["cpc"] <= cuts.bottom
    mask_top = kw_click["cpc"] >= cuts.top
    return {
        "rev_share_bottom": _share(mask_bottom, "revenue_14d", total_rev_all),
        "cost_share_bottom": _share(mask_bottom, "cost", total_cost_all),
        "rev_share_top": _share(mask_top, "revenue_14d", total_rev_all),
        "cost_share_top": _share(mask_top, "cost", total_cost_all),
    }

def _aov_p50(conv: pd.DataFrame) -> float:
    orders = conv["orders_14d"]; rev = conv["revenue_14d"]
    valid = rev[orders > 0] / orders[orders > 0]
    return float(valid.quantile(0.5)) if not valid.empty else 0.0

def _compute_exclusions(
    kw: pd.DataFrame, cuts: CpcCuts, aov_p50_value: float, breakeven_roas: float
) -> Dict[str, pd.DataFrame]:
    ex_a = kw[(kw["orders_14d"] == 0) & (kw["cpc"] >= cuts.top)].copy()
    ex_b = kw[(kw["orders_14d"] == 0) & (kw["cpc"] <= cuts.bottom) & (kw["clicks"] >= 1)].copy()
    cpc_global_p50 = float(kw.loc[kw["clicks"] > 0, "cpc"].quantile(0.5)) if (kw["clicks"] > 0).any() else 0.0
    ex_c = kw[kw["orders_14d"] == 0].copy()
    ex_c["next_click_cost"] = np.where(ex_c["cpc"] > 0, ex_c["cpc"], cpc_global_p50)
    ex_c["cost_after_1click"] = ex_c["cost"] + ex_c["next_click_cost"]
    ex_c["roas_if_1_order"] = (
        (aov_p50_value / ex_c["cost_after_1click"] * 100).replace([np.inf, -np.inf], 0).fillna(0).round(2)
        if aov_p50_value > 0 else 0.0
    )
    ex_c = ex_c[ex_c["roas_if_1_order"] <= float(breakeven_roas)].copy()
    ex_d = kw[(kw["roas_14d"] > 0) & (kw["roas_14d"] < float(breakeven_roas))].copy()
    return {"a": ex_a, "b": ex_b, "c": ex_c, "d": ex_d}

def _display_table(title: str, dff: pd.DataFrame, extra: Iterable[str] | None = None) -> None:
    cols = ["keyword","surface","active_days","impressions","clicks","cost","orders_14d","revenue_14d","ctr","cpc","roas_14d"]
    if extra: cols += list(extra)
    st.markdown(f"#### {title} ({len(dff)}ê°œ)")
    if dff.empty:
        return
    st.dataframe(dff.sort_values("cost", ascending=False)[cols].head(200), use_container_width=True, hide_index=True)

# ============== ì œì™¸ í‚¤ì›Œë“œ (í†µí•© í•œë°”êµ¬ë‹ˆ) ==============
def _gather_exclusion_keywords(exclusions: Dict[str, pd.DataFrame]) -> List[str]:
    seq: List[str] = []
    for label in ["a", "b", "c", "d"]:
        df = exclusions.get(label, pd.DataFrame())
        if not df.empty:
            seq.extend(df["keyword"].astype(str).tolist())
    return list(dict.fromkeys(seq))  # ìˆœì„œ ë³´ì¡´ ì¤‘ë³µ ì œê±°

def _format_keywords_line_exact(words: Iterable[str]) -> str:
    return ",\u200b".join([w for w in words])

def _copy_to_clipboard_button(label: str, text: str, key: str) -> None:
    """ì›¹ í´ë¦½ë³´ë“œ ê¶Œí•œ ì´ìŠˆë¥¼ ìš°íšŒ. ì™œ: í•œ ë²ˆì— ì „ë‹¬."""
    payload = json.dumps(text)
    html = f"""
    <div style="display:flex;align-items:center;gap:8px;">
      <button id="copybtn-{key}" role="button" aria-label="{label}"
        style="
          display:inline-flex;align-items:center;justify-content:center;
          padding:8px 12px;font-size:14px;line-height:1.25;
          border:1px solid rgba(49,51,63,0.2);border-radius:8px;background:#ffffff;cursor:pointer;
          box-shadow: 0 1px 2px rgba(0,0,0,0.04);transition: transform .02s, box-shadow .15s, background .15s;">
        {label}
      </button>
      <span id="copystat-{key}" style="font-size:13px;color:#4CAF50;"></span>
    </div>
    <script>
      const txt_{key} = {payload};
      const btn_{key} = document.getElementById("copybtn-{key}");
      const stat_{key} = document.getElementById("copystat-{key}");
      btn_{key}.onmouseenter = () => {{ btn_{key}.style.boxShadow = "0 2px 6px rgba(0,0,0,0.08)"; }};
      btn_{key}.onmouseleave = () => {{ btn_{key}.style.boxShadow = "0 1px 2px rgba(0,0,0,0.04)"; }};
      btn_{key}.onmousedown = () => {{ btn_{key}.style.transform = "scale(0.99)"; }};
      btn_{key}.onmouseup = () => {{ btn_{key}.style.transform = "scale(1)"; }};
      btn_{key}.onclick = async () => {{
        try {{
          await navigator.clipboard.writeText(txt_{key});
          stat_{key}.textContent = "ë³µì‚¬ë¨";
        }} catch (e) {{
          const area = document.createElement('textarea');
          area.value = txt_{key};
          area.style.position = 'fixed'; area.style.top = '-1000px';
          document.body.appendChild(area); area.focus(); area.select(); document.execCommand('copy');
          document.body.removeChild(area); stat_{key}.textContent = "ë³µì‚¬ë¨";
        }}
        setTimeout(()=> stat_{key}.textContent = "", 2000);
      }};
    </script>
    """
    components.html(html, height=56)

def _render_exclusion_union(exclusions: Dict[str, pd.DataFrame]) -> None:
    st.markdown("### 4) ì œì™¸í•œ í‚¤ì›Œë“œ (í†µí•© Â· í•œë°”êµ¬ë‹ˆ Â· ì¤‘ë³µ ì œê±°)")
    all_words = _gather_exclusion_keywords(exclusions)
    total = len(all_words)
    if total == 0:
        return
    line = _format_keywords_line_exact(all_words)
    _copy_to_clipboard_button(f"[ë³µì‚¬í•˜ê¸°] ì´{total}ê°œ", line, key="ex_union_copy")

# ============== ì €ì¥ ë¡œì§ (target_roas ì œê±°) ==============
def _save_to_supabase(
    supabase,
    *,
    upload,
    product_name: str,
    note: str,
    totals: Dict,
    breakeven_roas: float,
    cuts: CpcCuts,
    shares: Dict[str, float],
    aov_p50_value: float,
    kw: pd.DataFrame,
    exclusions: Dict[str, pd.DataFrame],
) -> None:
    run_id = str(uuid.uuid4())
    file_sha1 = hashlib.sha1(upload.getvalue()).hexdigest()
    st.caption(f"íŒŒì¼ í•´ì‹œ: {file_sha1[:12]}â€¦")
    supabase.table("ad_analysis_runs").insert(
        {
            "run_id": run_id,
            "product_name": product_name.strip(),
            "source_filename": upload.name,
            "source_rows": int(len(kw)),
            "date_min": str(totals.get("date_min")),
            "date_max": str(totals.get("date_max")),
            "note": note,
            "breakeven_roas": float(breakeven_roas),
            "cpc_cut": float(round(cuts.top, 2)),
        }
    ).execute()
    rows_kw = kw.assign(run_id=run_id)[
        ["run_id","keyword","surface","active_days","impressions","clicks","cost","orders_14d","revenue_14d","ctr","cpc","roas_14d"]
    ].to_dict(orient="records")
    for i in range(0, len(rows_kw), 1000):
        supabase.table("ad_analysis_keyword_total").upsert(rows_kw[i : i + 1000]).execute()
    artifacts = [
        {
            "run_id": run_id,
            "artifact_key": "settings",
            "payload": {
                "breakeven_roas": float(breakeven_roas),
                "cpc_cut_top": float(round(cuts.top, 2)),
                "cpc_cut_bottom": float(round(cuts.bottom, 2)),
                "top_rev_share": float(shares.get("rev_share_top", 0.0)),
                "bottom_rev_share": float(shares.get("rev_share_bottom", 0.0)),
                "aov_p50": float(aov_p50_value),
            },
        },
        {
            "run_id": run_id,
            "artifact_key": "exclusions",
            "payload": {
                "a": exclusions["a"]["keyword"].tolist(),
                "b": exclusions["b"]["keyword"].tolist(),
                "c": exclusions["c"]["keyword"].tolist(),
                "d": exclusions["d"]["keyword"].tolist(),
            },
        },
    ]
    supabase.table("ad_analysis_artifacts").upsert(artifacts).execute()
    st.success(f"ì €ì¥ ì„±ê³µ (ID: {run_id})")

# ============== Streamlit íƒ­ ==============
def render_ad_analysis_tab(supabase):
    st.subheader("ê´‘ê³ ë¶„ì„ (ì´ 14ì¼ ê¸°ì¤€)")
    up = st.file_uploader("ë¡œìš°ë°ì´í„° ì—…ë¡œë“œ (xlsx/csv)", type=["xlsx", "csv"], key="ad_up")

    breakeven_roas = st.number_input("ì†ìµë¶„ê¸° ROAS", min_value=0.0, value=0.0, step=10.0, key="ad_be")

    run = st.button("ğŸ” ë¶„ì„í•˜ê¸°", key="ad_run", use_container_width=True)
    if not run:
        return

    if up is None:
        st.error("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return

    try:
        df_raw = _load_df(up)
        df = _normalize(df_raw)
    except ValueError as e:
        st.error(str(e)); return
    if df.empty:
        st.error("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return

    kw, totals = _aggregate_kw(df)

    st.markdown("### 1) ê¸°ë³¸ ì„±ê³¼ ì§€í‘œ")
    st.caption(f"ê¸°ê°„: {totals['date_min']} ~ {totals['date_max']}")
    total_cost = totals["total_cost"]; total_rev = totals["total_rev"]; total_orders = totals["total_orders"]
    def _row(name: str, sub: pd.DataFrame) -> Dict[str, float | int | str]:
        c, r, o = int(sub["cost"].sum()), int(sub["revenue_14d"].sum()), int(sub["orders_14d"].sum())
        return {
            "ì˜ì—­": name, "ê´‘ê³ ë¹„": c,
            "ê´‘ê³ ë¹„ë¹„ìœ¨(%)": round(_safe_div(c, total_cost) * 100, 2),
            "ë§¤ì¶œ": r, "ë§¤ì¶œë¹„ìœ¨(%)": round(_safe_div(r, total_rev) * 100, 2),
            "ì£¼ë¬¸": o, "ì£¼ë¬¸ë¹„ìœ¨(%)": round(_safe_div(o, total_orders) * 100, 2),
            "ROAS": round(_safe_div(r, c) * 100, 2),
        }
    rows = [
        _row("ì „ì²´", df),
        _row("ê²€ìƒ‰", df[df["surface"] == SURF_SEARCH_VALUE]),
        _row("ë¹„ê²€ìƒ‰", df[df["surface"] != SURF_SEARCH_VALUE]),
    ]
    st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

    st.markdown("### 2) CPC-ëˆ„ì ë§¤ì¶œ ë¹„ì¤‘ & ì»·")
    cuts, conv = _compute_cpc_cuts(kw)
    if conv.empty:
        shares = {"rev_share_bottom": 0.0, "cost_share_bottom": 0.0, "rev_share_top": 0.0, "cost_share_top": 0.0}
        aov50 = 0.0
        st.caption("ì „í™˜ ë°œìƒ í‚¤ì›Œë“œê°€ ì—†ì–´ ì»·ì€ 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
    else:
        chart = alt.Chart(conv).mark_line().encode(x="cpc:Q", y="cum_rev_share:Q")
        vline_bottom = alt.Chart(pd.DataFrame({"c": [cuts.bottom]})).mark_rule(strokeDash=[2, 2]).encode(x="c:Q")
        vline_top = alt.Chart(pd.DataFrame({"c": [cuts.top]})).mark_rule(strokeDash=[6, 4]).encode(x="c:Q")
        st.altair_chart(chart + vline_bottom + vline_top, use_container_width=True)
        shares = _search_shares_for_cuts(kw, cuts)
        aov50 = _aov_p50(conv)

        st.caption("ë¹„ì¤‘ ë¶„ëª¨: ì „ì²´ ì±„ë„(ê²€ìƒ‰+ë¹„ê²€ìƒ‰), ë¶„ì: ê²€ìƒ‰ ì˜ì—­(í´ë¦­>0) ì¤‘ CPC ì¡°ê±´ ì¶©ì¡± í‚¤ì›Œë“œ í•©")

        st.markdown(
            f"""
- **CPC_cut bottom:** {round(cuts.bottom, 2)}ì›  
  Â· ê²€ìƒ‰ ê´‘ê³  ë§¤ì¶œ ë¹„ì¤‘ {shares['rev_share_bottom']}%  
  Â· ê²€ìƒ‰ ê´‘ê³  ê´‘ê³ ë¹„ ë¹„ì¤‘ {shares['cost_share_bottom']}%

- **CPC_cut top:** {round(cuts.top, 2)}ì›  
  Â· ê²€ìƒ‰ ê´‘ê³  ë§¤ì¶œ ë¹„ì¤‘ {shares['rev_share_top']}%  
  Â· ê²€ìƒ‰ ê´‘ê³  ê´‘ê³ ë¹„ ë¹„ì¤‘ {shares['cost_share_top']}%
"""
        )

    st.markdown("### 3) ì œì™¸ í‚¤ì›Œë“œ")
    exclusions = _compute_exclusions(kw, cuts, aov50, float(breakeven_roas))
    _display_table("a) CPC_cut top ì´ìƒ ì „í™˜ 0", exclusions["a"])
    _display_table("b) CPC_cut bottom ì´í•˜ ì „í™˜ 0", exclusions["b"])
    _display_table("c) ì „í™˜ ì‹œ ì†ìµ ROAS ë¯¸ë‹¬", exclusions["c"], extra=["roas_if_1_order"])
    _display_table("d) ì†ìµ ROAS ë¯¸ë‹¬", exclusions["d"])

    _render_exclusion_union(exclusions)

    with st.expander("ğŸ’¾ ì €ì¥ (ì„ íƒ)", expanded=False):
        c1, c2 = st.columns([2, 3])
        with c1: product_name = st.text_input("ìƒí’ˆëª…", value="", key="ad_product")
        with c2: note = st.text_input("ë©”ëª¨", value="", key="ad_note")
        can_save = bool(product_name.strip())
        save_btn = st.button("âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥", disabled=not can_save, key="ad_save")
        if save_btn and can_save:
            try:
                _save_to_supabase(
                    supabase,
                    upload=up,
                    product_name=product_name,
                    note=note,
                    totals=totals,
                    breakeven_roas=float(breakeven_roas),
                    cuts=cuts,
                    shares=shares,
                    aov_p50_value=aov50,
                    kw=kw,
                    exclusions=exclusions,
                )
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")
